
@inproceedings{bammey_demosaicing_2022,
	address = {Shanghai, China},
	title = {Demosaicing to {Detect} {Demosaicing} and {Image} {Forgeries}},
	isbn = {9798350309676},
	url = {https://ieeexplore.ieee.org/document/9975454/},
	doi = {10.1109/WIFS55849.2022.9975454},
	abstract = {The trustfulness of images is a critical concern. Digital photographs can no longer be assumed to be truthful; indeed, digital image editing tools can easily and convincingly alter the semantic content of an image. Being able to analyse an image to check for forgeries becomes of the utmost importance in many domains, from police investigations to fact-checking and journalism. We propose here to analyse traces left by the camera during demosaicing, one of the first steps of image formation. When an object is added or displaced on an image, the demosaicing traces can be disrupted, leaving forgery clues. In order to detect these inconsistencies, we explore the possibilities offered by double demosaicing. Computing the demosaicing residual of an image with different demosaicing algorithms and patterns enables one to find image regions with inconsistent demosaicing traces. We render the method fully automatic by a simple a contrario scheme computing forgery detection thresholds with statistical guarantees on the number of false alarms.},
	language = {en},
	urldate = {2023-03-03},
	booktitle = {2022 {IEEE} {International} {Workshop} on {Information} {Forensics} and {Security} ({WIFS})},
	publisher = {IEEE},
	author = {Bammey, Quentin and Von Gioi, Rafael Grompone and Morel, Jean-Michel},
	month = dec,
	year = {2022},
	pages = {1--6},
	file = {Bammey et al. - 2022 - Demosaicing to Detect Demosaicing and Image Forger.pdf:/Users/jeremie/Zotero/storage/9R5ZF8I2/Bammey et al. - 2022 - Demosaicing to Detect Demosaicing and Image Forger.pdf:application/pdf},
}

@misc{bammey_non-semantic_2021,
	title = {Non-{Semantic} {Evaluation} of {Image} {Forensics} {Tools}: {Methodology} and {Database}},
	shorttitle = {Non-{Semantic} {Evaluation} of {Image} {Forensics} {Tools}},
	url = {http://arxiv.org/abs/2105.02700},
	doi = {10.48550/arXiv.2105.02700},
	abstract = {With the aim of evaluating image forensics tools, we propose a methodology to create forgeries traces, leaving intact the semantics of the image. Thus, the only forgery cues left are the specific alterations of one or several aspects of the image formation pipeline. This methodology creates automatically forged images that are challenging to detect for forensic tools and overcomes the problem of creating convincing semantic forgeries. Based on this methodology, we create the Trace database and conduct an evaluation of the main state-of-the-art image forensics tools.},
	urldate = {2023-03-03},
	publisher = {arXiv},
	author = {Bammey, Quentin and Nikoukhah, Tina and Gardella, Marina and Grompone, Rafael and Colom, Miguel and Morel, Jean-Michel},
	month = may,
	year = {2021},
	note = {arXiv:2105.02700 [eess]},
	keywords = {Electrical Engineering and Systems Science - Image and Video Processing, Electrical Engineering and Systems Science - Signal Processing},
	file = {arXiv Fulltext PDF:/Users/jeremie/Zotero/storage/9ZILFI9D/Bammey et al. - 2021 - Non-Semantic Evaluation of Image Forensics Tools .pdf:application/pdf;arXiv.org Snapshot:/Users/jeremie/Zotero/storage/JFWD5JIV/2105.html:text/html},
}

@article{menon_demosaicing_2007,
	title = {Demosaicing {With} {Directional} {Filtering} and a posteriori {Decision}},
	volume = {16},
	issn = {1057-7149},
	url = {http://ieeexplore.ieee.org/document/4032820/},
	doi = {10.1109/TIP.2006.884928},
	abstract = {Most digital cameras use a color ﬁlter array to capture the colors of the scene. Downsampled versions of the red, green, and blue components are acquired, and an interpolation of the three colors is necessary to reconstruct a full representation of the image. This color interpolation is known as demosaicing. The most effective demosaicing techniques proposed in the literature are based on directional ﬁltering and a posteriori decision. In this paper, we present a novel approach to this reconstruction method. A reﬁning step is included to further improve the resulting reconstructed image. The proposed approach requires a limited computational cost and gives good performance even when compared to more demanding techniques.},
	language = {en},
	number = {1},
	urldate = {2023-03-10},
	journal = {IEEE Transactions on Image Processing},
	author = {Menon, Daniele and Andriani, Stefano and Calvagno, Giancarlo},
	month = jan,
	year = {2007},
	pages = {132--141},
	file = {Menon et al. - 2007 - Demosaicing With Directional Filtering and a poste.pdf:/Users/jeremie/Zotero/storage/5PCECZ2H/Menon et al. - 2007 - Demosaicing With Directional Filtering and a poste.pdf:application/pdf},
}

@book{malvar_high-quality_2004,
	title = {High-quality linear interpolation for demosaicing of {Bayer}-patterned color images},
	volume = {3},
	isbn = {978-0-7803-8484-2},
	abstract = {This paper introduces a new interpolation technique for demosaicing of color images produced by single-CCD digital cameras. We show that the proposed simple linear filter can lead to an improvement in PSNR of over 5.5 dB when compared to bilinear demosaicing, and about 0.7 dB improvement in R and B interpolation when compared to a recently introduced linear interpolator. The proposed filter also outperforms most nonlinear demosaicing algorithms, without the artifacts due to nonlinear processing, and a much reduced computational complexity.},
	author = {Malvar, Henrique and He, Li-wei and Cutler, Ross},
	month = jun,
	year = {2004},
	doi = {10.1109/ICASSP.2004.1326587},
	note = {Journal Abbreviation: Acoustics, Speech, and Signal Processing, 1988. ICASSP-88., 1988 International Conference on
Pages: 485
Publication Title: Acoustics, Speech, and Signal Processing, 1988. ICASSP-88., 1988 International Conference on},
	file = {Full Text PDF:/Users/jeremie/Zotero/storage/73ZKPI2C/Malvar et al. - 2004 - High-quality linear interpolation for demosaicing .pdf:application/pdf},
}

@article{skodras_jpeg_2001,
	title = {The {JPEG} 2000 still image compression standard},
	volume = {18},
	issn = {1558-0792},
	doi = {10.1109/79.952804},
	abstract = {One of the aims of the standardization committee has been the development of Part I, which could be used on a royalty- and fee-free basis. This is important for the standard to become widely accepted. The standardization process, which is coordinated by the JTCI/SC29/WG1 of the ISO/IEC has already produced the international standard (IS) for Part I. In this article the structure of Part I of the JPFG 2000 standard is presented and performance comparisons with established standards are reported. This article is intended to serve as a tutorial for the JPEG 2000 standard. The main application areas and their requirements are given. The architecture of the standard follows with the description of the tiling, multicomponent transformations, wavelet transforms, quantization and entropy coding. Some of the most significant features of the standard are presented, such as region-of-interest coding, scalability, visual weighting, error resilience and file format aspects. Finally, some comparative results are reported and the future parts of the standard are discussed.},
	number = {5},
	journal = {IEEE Signal Processing Magazine},
	author = {Skodras, A. and Christopoulos, C. and Ebrahimi, T.},
	month = sep,
	year = {2001},
	note = {Conference Name: IEEE Signal Processing Magazine},
	keywords = {Entropy coding, IEC standards, Image coding, ISO standards, Quantization, Resilience, Scalability, Standardization, Transform coding, Wavelet transforms},
	pages = {36--58},
	file = {IEEE Xplore Abstract Record:/Users/jeremie/Zotero/storage/S2CWBQN4/952804.html:text/html;Texte intégral:/Users/jeremie/Zotero/storage/MG6S27JU/Skodras et al. - 2001 - The JPEG 2000 still image compression standard.pdf:application/pdf},
}

@article{popescu_exposing_2005,
	title = {Exposing digital forgeries in color filter array interpolated images},
	volume = {53},
	issn = {1941-0476},
	doi = {10.1109/TSP.2005.855406},
	abstract = {With the advent of low-cost and high-resolution digital cameras, and sophisticated photo editing software, digital images can be easily manipulated and altered. Although good forgeries may leave no visual clues of having been tampered with, they may, nevertheless, alter the underlying statistics of an image. Most digital cameras, for example, employ a single sensor in conjunction with a color filter array (CFA), and then interpolate the missing color samples to obtain a three channel color image. This interpolation introduces specific correlations which are likely to be destroyed when tampering with an image. We quantify the specific correlations introduced by CFA interpolation, and describe how these correlations, or lack thereof, can be automatically detected in any portion of an image. We show the efficacy of this approach in revealing traces of digital tampering in lossless and lossy compressed color images interpolated with several different CFA algorithms.},
	number = {10},
	journal = {IEEE Transactions on Signal Processing},
	author = {Popescu, A.C. and Farid, H.},
	month = oct,
	year = {2005},
	note = {Conference Name: IEEE Transactions on Signal Processing},
	keywords = {Image coding, Color, Digital cameras, Digital filters, Digital forensics, Digital images, digital tampering, Forgery, Image sensors, Interpolation, Sensor arrays, Statistics},
	pages = {3948--3959},
}

@article{ferrara_image_2012,
	title = {Image {Forgery} {Localization} via {Fine}-{Grained} {Analysis} of {CFA} {Artifacts}},
	volume = {7},
	issn = {1556-6021},
	doi = {10.1109/TIFS.2012.2202227},
	abstract = {In this paper, a forensic tool able to discriminate between original and forged regions in an image captured by a digital camera is presented. We make the assumption that the image is acquired using a Color Filter Array, and that tampering removes the artifacts due to the demosaicking algorithm. The proposed method is based on a new feature measuring the presence of demosaicking artifacts at a local level, and on a new statistical model allowing to derive the tampering probability of each 2 × 2 image block without requiring to know a priori the position of the forged region. Experimental results on different cameras equipped with different demosaicking algorithms demonstrate both the validity of the theoretical model and the effectiveness of our scheme.},
	number = {5},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Ferrara, Pasquale and Bianchi, Tiziano and De Rosa, Alessia and Piva, Alessandro},
	month = oct,
	year = {2012},
	note = {Conference Name: IEEE Transactions on Information Forensics and Security},
	keywords = {Digital cameras, Forgery, Interpolation, CFA artifacts, Classification algorithms, digital camera demosaicking, Forensics, forgery localization, Image color analysis, image forensics, Kernel, tampering probability map},
	pages = {1566--1577},
	file = {IEEE Xplore Abstract Record:/Users/jeremie/Zotero/storage/JK8P65UD/6210378.html:text/html;Texte intégral:/Users/jeremie/Zotero/storage/F9X95A9W/Ferrara et al. - 2012 - Image Forgery Localization via Fine-Grained Analys.pdf:application/pdf},
}

@inproceedings{memon_detection_2010,
	address = {San Jose, California},
	title = {On detection of median filtering in digital images},
	url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.839100},
	doi = {10.1117/12.839100},
	abstract = {In digital image forensics, it is generally accepted that intentional manipulations of the image content are most critical and hence numerous forensic methods focus on the detection of such ‘malicious’ post-processing. However, it is also beneﬁcial to know as much as possible about the general processing history of an image, including content-preserving operations, since they can aﬀect the reliability of forensic methods in various ways. In this paper, we present a simple yet eﬀective technique to detect median ﬁltering in digital images—a widely used denoising and smoothing operator. As a great variety of forensic methods relies on some kind of a linearity assumption, a detection of non-linear median ﬁltering is of particular interest. The eﬀectiveness of our method is backed with experimental evidence on a large image database.},
	language = {en},
	urldate = {2023-03-20},
	author = {Kirchner, Matthias and Fridrich, Jessica},
	editor = {Memon, Nasir D. and Dittmann, Jana and Alattar, Adnan M. and Delp III, Edward J.},
	month = feb,
	year = {2010},
	pages = {754110},
	file = {Kirchner et Fridrich - 2010 - On detection of median filtering in digital images.pdf:/Users/jeremie/Zotero/storage/4F9TRWVS/Kirchner et Fridrich - 2010 - On detection of median filtering in digital images.pdf:application/pdf},
}

@inproceedings{milani_demosaicing_2014,
	title = {Demosaicing strategy identification via eigenalgorithms},
	doi = {10.1109/ICASSP.2014.6854082},
	abstract = {The identification of the camera that has acquired a specific image can be performed via several device-related footprints. Among these, it is possible to look for the traces left by the adopted color demosaicing strategy, which varies according to the camera model and vendor. The paper presents an identification strategy that re-processes the analyzed image with a set of distinctive CFA interpolation algorithms (eigenalgorithms) and, according to the correlation of the output with the original image, builds a set of features that permits identifying the algorithm. The proposed solution performs well with respect to other state-of-the-art solutions also when the analyzed image is severely compressed.},
	booktitle = {2014 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Milani, Simone and Bestagini, Paolo and Tagliasacchi, Marco and Tubaro, Stefano},
	month = may,
	year = {2014},
	note = {ISSN: 2379-190X},
	keywords = {Conferences, Image coding, Transform coding, Interpolation, Image color analysis, image forensics, Algorithm design and analysis, Bayer mask, Cameras, CFA interpolation, demosaicing identification, device identification},
	pages = {2659--2663},
	file = {IEEE Xplore Abstract Record:/Users/jeremie/Zotero/storage/RMGQXIUQ/6854082.html:text/html},
}

@misc{noauthor_cfa_nodate,
	title = {{CFA} pattern identification of digital cameras using intermediate value counting {\textbar} {Proceedings} of the thirteenth {ACM} multimedia workshop on {Multimedia} and security},
	url = {https://dl.acm.org/doi/10.1145/2037252.2037258},
	urldate = {2023-03-20},
	file = {CFA pattern identification of digital cameras using intermediate value counting | Proceedings of the thirteenth ACM multimedia workshop on Multimedia and security:/Users/jeremie/Zotero/storage/YB62IMBD/2037252.html:text/html},
}

@article{bammey_image_2021,
	title = {Image {Forgeries} {Detection} through {Mosaic} {Analysis}: the {Intermediate} {Values} {Algorithm}},
	volume = {11},
	issn = {2105-1232},
	shorttitle = {Image {Forgeries} {Detection} through {Mosaic} {Analysis}},
	url = {https://www.ipol.im/pub/art/2021/355/?utm_source=doi},
	doi = {10.5201/ipol.2021.355},
	abstract = {Cameras sample each image pixel in one color channel only. The remaining channels are interpolated from neighboring pixels during demosaicing. This operation leaves traces, that can be exploited to authentify images and detect forgeries. This paper describes the method introduced by Choi et al. that exploits the fact that interpolated pixels are more prone to be intermediate values, to detect in which pattern an image has been sampled. We then use this information to ﬁnd regions that are inconsistent with the global image. We attribute a conﬁdence score to each detection, which can then be thresholded to provide a binary map of detected forgeries.},
	language = {en},
	urldate = {2023-03-20},
	journal = {Image Processing On Line},
	author = {Bammey, Quentin and Grompone von Gioi, Rafael and Morel, Jean-Michel},
	month = oct,
	year = {2021},
	pages = {317--343},
	file = {Bammey et al. - 2021 - Image Forgeries Detection through Mosaic Analysis.pdf:/Users/jeremie/Zotero/storage/H63B6XXC/Bammey et al. - 2021 - Image Forgeries Detection through Mosaic Analysis.pdf:application/pdf},
}

@inproceedings{bammey_adaptive_2020,
	address = {Seattle, WA, USA},
	title = {An {Adaptive} {Neural} {Network} for {Unsupervised} {Mosaic} {Consistency} {Analysis} in {Image} {Forensics}},
	isbn = {978-1-72817-168-5},
	url = {https://ieeexplore.ieee.org/document/9157017/},
	doi = {10.1109/CVPR42600.2020.01420},
	abstract = {Automatically ﬁnding suspicious regions in a potentially forged image by splicing, inpainting or copy-move remains a widely open problem. Blind detection neural networks trained on benchmark data are ﬂourishing. Yet, these methods do not provide an explanation of their detections. The more traditional methods try to provide such evidence by pointing out local inconsistencies in the image noise, JPEG compression, chromatic aberration, or in the mosaic. In this paper we develop a blind method that can train directly on unlabelled and potentially forged images to point out local mosaic inconsistencies. To this aim we designed a CNN structure inspired from demosaicing algorithms and directed at classifying image blocks by their position in the image modulo (2 × 2). Creating a diversiﬁed benchmark database using varied demosaicing methods, we explore the efﬁciency of the method and its ability to adapt quickly to any new data.},
	language = {en},
	urldate = {2023-03-20},
	booktitle = {2020 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Bammey, Quentin and von Gioi, Rafael Grompone and Morel, Jean-Michel},
	month = jun,
	year = {2020},
	pages = {14182--14192},
	file = {Bammey et al. - 2020 - An Adaptive Neural Network for Unsupervised Mosaic.pdf:/Users/jeremie/Zotero/storage/ZEZ96CRX/Bammey et al. - 2020 - An Adaptive Neural Network for Unsupervised Mosaic.pdf:application/pdf},
}

@article{park_image_2021,
	title = {Image {Tampering} {Localization} {Using} {Demosaicing} {Patterns} and {Singular} {Value} {Based} {Prediction} {Residue}},
	volume = {9},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2021.3091161},
	abstract = {Almost all image sensors measure only one color per pixel through the color filter array. Missing pixels are estimated using a demosaicing process. For this reason, a demosaiced image leaves a particular trace. When an image is manipulated or tampered, the demosaicing trace can be changed. This change can serve as a basic clue for detecting or localizing image tampering. Demosaicing pattern-based tampering localization algorithms require a re-interpolation process, and the prediction residue between the given image and the re-interpolated image is commonly used to localize tampered regions. However, the prediction residue is not always valid because the demosaicing interpolation kernel cannot be known, which deteriorates the localization performance. This paper presents an effective re-interpolation process using singular value decomposition for an unknown demosaicing method. First, the green channel of the given image is decomposed into four sub-images according to the Bayer pattern. For a small block of each sub-image, the singular value decomposition is performed. The prediction residue is obtained by reconstructing the image block after removing the largest singular value. The feature to localize the forged regions is extracted by the logarithm ratio of the prediction residue variance. The proposed method does not require any statistical model for the extracted feature, because the prediction residue is more accurate than that of conventional methods. We perform intensive experiments for three test datasets and compare the proposed method with state-of-the-art tampering localization methods, the results of which indicate that the proposed scheme outperforms existing approaches.},
	journal = {IEEE Access},
	author = {Park, Cheol Woo and Moon, Yong Ho and Eom, Il Kyu},
	year = {2021},
	note = {Conference Name: IEEE Access},
	keywords = {Feature extraction, Forgery, Interpolation, Image color analysis, Kernel, color filter array, demosaicing trace, image splicing, Image tampering localization, Location awareness, prediction residue, re-interpolation kernel, singular value decomposition, Splicing},
	pages = {91921--91933},
	file = {IEEE Xplore Abstract Record:/Users/jeremie/Zotero/storage/HVFIIGQD/stamp.html:text/html;IEEE Xplore Full Text PDF:/Users/jeremie/Zotero/storage/E7B5M8DL/Park et al. - 2021 - Image Tampering Localization Using Demosaicing Pat.pdf:application/pdf},
}

@inproceedings{bammey_forgery_2022,
	address = {Waikoloa, HI, USA},
	title = {Forgery {Detection} by {Internal} {Positional} {Learning} of {Demosaicing} {Traces}},
	isbn = {978-1-66540-915-5},
	url = {https://ieeexplore.ieee.org/document/9707020/},
	doi = {10.1109/WACV51458.2022.00109},
	abstract = {We propose 4Point (Forensics with Positional Internal Training), an unsupervised neural network trained to assess the consistency of the image colour mosaic to ﬁnd forgeries. Positional learning trains the model to learn the modulo-2 position of pixels, leveraging the translation-invariance of CNN to replicate the underlying mosaic and its potential inconsistencies. Internal learning on a single potentially forged image improves adaption and robustness to varied post-processing and counter-forensics measures. This solution beats existing mosaic detection methods, is more robust to various post-processing and counter-forensic artefacts such as JPEG compression, and can exploit traces to which state-of-the-art generic neural networks are blind. Check qbammey.github.io/4point for the code.},
	language = {en},
	urldate = {2023-03-21},
	booktitle = {2022 {IEEE}/{CVF} {Winter} {Conference} on {Applications} of {Computer} {Vision} ({WACV})},
	publisher = {IEEE},
	author = {Bammey, Quentin and von Gioi, Rafael Grompone and Morel, Jean-Michel},
	month = jan,
	year = {2022},
	pages = {1019--1029},
	file = {Bammey et al. - 2022 - Forgery Detection by Internal Positional Learning .pdf:/Users/jeremie/Zotero/storage/AXUMQVGT/Bammey et al. - 2022 - Forgery Detection by Internal Positional Learning .pdf:application/pdf},
}

@misc{noauthor_detection_nodate,
	title = {Detection {Theory} and {Industrial} {Applications} jean michel morel 2021 - {Recherche} {Google}},
	url = {https://www.google.com/search?client=safari&rls=en&q=Detection+Theory+and+Industrial+Applications+jean+michel+morel+2021&ie=UTF-8&oe=UTF-8},
	urldate = {2023-03-21},
	file = {detection_theory_lecture_notes.pdf:/Users/jeremie/Zotero/storage/AY3PHZII/search.html:text/html},
}

@book{morel_detection_2021,
	title = {Detection {Theory} and {Industrial} {Applications}},
	url = {http://dev.ipol.im/~qbammey/anne/detection_theory_lecture_notes.pdf},
	language = {en},
	author = {Morel, Jean-Michel and Grompone von Gioi, Rafael},
	year = {2021},
	file = {Morel - Detection Theory and Industrial Applications.pdf:/Users/jeremie/Zotero/storage/GGIVN3FN/Morel - Detection Theory and Industrial Applications.pdf:application/pdf},
}

@book{von_ehrenfels_uber_1890,
	title = {Über "{Gestaltqualitäten}"},
	url = {https://phaenomenologica.de/wp-content/uploads/2019/02/CvEhrenfels_Gestaltqualitaeten.pdf},
	publisher = {Reisland},
	author = {von Ehrenfels, Christian},
	year = {1890},
}

@misc{dentan_dataset_2023,
	title = {Dataset dall-e-images},
	url = {https://gist.github.com/DentanJeremie/21bfd925c5234afd15d854135b569bec},
	author = {Dentan, Jérémie},
	year = {2023},
}

@misc{colom_noise_2023,
	title = {Noise free test images},
	url = {https://mcolom.perso.math.cnrs.fr/pages/no_noise_images/},
	urldate = {2023-03-22},
	author = {Colom, Miguel},
	year = {2023},
	file = {Noise free test images:/Users/jeremie/Zotero/storage/QP35J2SZ/no_noise_images.html:text/html},
}

@misc{ramesh_hierarchical_2022,
	title = {Hierarchical {Text}-{Conditional} {Image} {Generation} with {CLIP} {Latents}},
	url = {http://arxiv.org/abs/2204.06125},
	doi = {10.48550/arXiv.2204.06125},
	abstract = {Contrastive models like CLIP have been shown to learn robust representations of images that capture both semantics and style. To leverage these representations for image generation, we propose a two-stage model: a prior that generates a CLIP image embedding given a text caption, and a decoder that generates an image conditioned on the image embedding. We show that explicitly generating image representations improves image diversity with minimal loss in photorealism and caption similarity. Our decoders conditioned on image representations can also produce variations of an image that preserve both its semantics and style, while varying the non-essential details absent from the image representation. Moreover, the joint embedding space of CLIP enables language-guided image manipulations in a zero-shot fashion. We use diffusion models for the decoder and experiment with both autoregressive and diffusion models for the prior, finding that the latter are computationally more efficient and produce higher-quality samples.},
	urldate = {2023-03-24},
	publisher = {arXiv},
	author = {Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
	month = apr,
	year = {2022},
	note = {arXiv:2204.06125 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/jeremie/Zotero/storage/4J68GLJ5/Ramesh et al. - 2022 - Hierarchical Text-Conditional Image Generation wit.pdf:application/pdf},
}

